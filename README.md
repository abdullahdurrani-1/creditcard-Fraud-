# creditcard-Fraud-
Here is a complete **`README.md`** for your **Credit Card Fraud Detection Project**

---

````markdown
# ðŸ’³ Credit Card Fraud Detection using Supervised Learning



## ðŸ“Œ Project Overview

This project focuses on detecting fraudulent credit card transactions using supervised machine learning algorithms, particularly **Logistic Regression** and **Random Forest**. The dataset is highly imbalanced, which poses a challenge and requires proper preprocessing and evaluation strategies.

---

## ðŸ“ Dataset Description

- **Source**: Kaggle ([Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud))
- **Size**: 284,807 transactions
- **Target**: `Class` (1 = Fraud, 0 = Non-Fraud)
- **Features**: 30 anonymized numerical features + `Time`, `Amount`

---

## âš™ï¸ Machine Learning Pipeline

### ðŸ”¹ 1. **Data Preprocessing**
- Applied **StandardScaler** to `Amount` and `Time`
- Dropped scaled columns after transformation
- Checked for nulls and unique values

### ðŸ”¹ 2. **Train-Test Split**
```python
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)
````

### ðŸ”¹ 3. **Modeling**

* **Logistic Regression** as a baseline
* **Random Forest Classifier** (with `class_weight='balanced'`) to handle class imbalance

### ðŸ”¹ 4. **Evaluation Metrics**

* Confusion Matrix
* Precision, Recall, F1 Score
* **ROC Curve & AUC**
* Feature Importance Plot

### ðŸ”¹ 5. **Hyperparameter Tuning**

```python
GridSearchCV(RandomForestClassifier(), param_grid, scoring='f1', cv=3)
```

---

## ðŸ“Š Results Summary

| Metric    | Logistic Regression | Random Forest |
| --------- | ------------------- | ------------- |
| Accuracy  | 99.4%               | âœ… Excellent   |
| Precision | 94.5%               | âœ… Excellent   |
| Recall    | 70%                 | âœ… Good        |
| F1 Score  | 80.2%               | âœ… Strong      |
| ROC-AUC   | 97.9%               | âœ… Very High   |

* **Best Parameters (RF)**: `n_estimators=200`, `max_depth=20`, `class_weight='balanced'`
* **Top Features**: V14, V17, V12, V10, V4

---

## ðŸ“ˆ Visualizations

* ðŸ” ROC Curve
* ðŸ“Š Class Distribution
* ðŸ“‰ Correlation Heatmap
* ðŸ“Œ Feature Importance
* ðŸ’° Transaction Distribution

---

## ðŸ¤– Algorithms Used

| Algorithm           | Type                | Why Used?                               |
| ------------------- | ------------------- | --------------------------------------- |
| Logistic Regression | Linear Classifier   | Quick baseline model, interpretable     |
| Random Forest       | Ensemble Classifier | Handles imbalance, non-linear relations |

---

## ðŸ’¡ Lessons Learned

* Proper preprocessing and scaling improves model reliability.
* Class imbalance requires **class weights** or **resampling**.
* ROC & F1-Score are more meaningful than accuracy for imbalanced datasets.
* Feature importance gives insight into what drives fraud detection.


---

## ðŸ“š Future Improvements

* Use SMOTE or ADASYN for synthetic oversampling
* Try other models: XGBoost, LightGBM
* Deploy with Flask or Streamlit for real-time predictions

---

## ðŸ™Œ Acknowledgements

* Scikit-Learn, Matplotlib, Seaborn

---

## ðŸ§  Author

**Abdullah Durrani**
*Student of BS Statistics | Future AI Expert | Poetic Soul on a Mission to Oxford*
ðŸŒ Pakistan
ðŸš€ Learning ML, DS, Agentic AI â€” devlepor



> **â€“ Abdullah Durrani**
```
